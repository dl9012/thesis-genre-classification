{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Genre Classification with LSTM\n",
    "## Document-level approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "RANDOM_STATE = 1212\n",
    "\n",
    "cmu_data = pd.read_csv('cmu_data_final.csv')\n",
    "imdb_data = pd.read_csv('imdb_data_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and token.isalnum()]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "cmu_data['processed_plot'] = cmu_data['plot'].apply(preprocess_text)\n",
    "imdb_data['processed_plot'] = imdb_data['plot'].apply(preprocess_text)\n",
    "\n",
    "# Choose either the CMU embeddings or the Google News embeddings\n",
    "\n",
    "# Word2vec embeddings, trained on the CMU dataset\n",
    "# word2vec_model = KeyedVectors.load('word2vec_model_from_cmu_utf8.bin')\n",
    "\n",
    "# Google news word2vec embeddings\n",
    "import gensim.downloader as api\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad the text sequences\n",
    "cmu_tokenizer = Tokenizer()\n",
    "cmu_tokenizer.fit_on_texts(cmu_data['processed_plot'])\n",
    "cmu_sequences = cmu_tokenizer.texts_to_sequences(cmu_data['processed_plot'])\n",
    "cmu_word_index = cmu_tokenizer.word_index\n",
    "cmu_padded_sequences = pad_sequences(cmu_sequences, maxlen=300)\n",
    "\n",
    "# Label encoding\n",
    "cmu_data['genre'] = cmu_data['genre'].apply(lambda x: x.split('|'))\n",
    "cmu_mlb = MultiLabelBinarizer()\n",
    "cmu_genres_encoded = cmu_mlb.fit_transform(cmu_data['genre'])\n",
    "\n",
    "# Train-test split\n",
    "cmu_X_train, cmu_X_test, cmu_y_train, cmu_y_test = train_test_split(\n",
    "    cmu_padded_sequences, cmu_genres_encoded, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad the text sequences\n",
    "imdb_tokenizer = Tokenizer()\n",
    "imdb_tokenizer.fit_on_texts(imdb_data['processed_plot'])\n",
    "imdb_sequences = imdb_tokenizer.texts_to_sequences(imdb_data['processed_plot'])\n",
    "imdb_word_index = imdb_tokenizer.word_index\n",
    "imdb_padded_sequences = pad_sequences(imdb_sequences, maxlen=300)\n",
    "\n",
    "# Label encoding\n",
    "imdb_data['genre'] = imdb_data['genre'].apply(lambda x: x.split('|'))\n",
    "imdb_mlb = MultiLabelBinarizer()\n",
    "imdb_genres_encoded = imdb_mlb.fit_transform(imdb_data['genre'])\n",
    "\n",
    "# Train-test split\n",
    "imdb_X_train, imdb_X_test, imdb_y_train, imdb_y_test = train_test_split(\n",
    "    imdb_padded_sequences, imdb_genres_encoded, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CMU embedding matrix\n",
    "\"\"\" cmu_embedding_dim = word2vec_model.vector_size\n",
    "cmu_embedding_matrix = np.zeros((len(cmu_word_index) + 1, cmu_embedding_dim))\n",
    "for word, i in cmu_word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        cmu_embedding_matrix[i] = word2vec_model.wv[word] \"\"\"\n",
    "\n",
    "# Create the Google News embedding matrix\n",
    "cmu_embedding_dim = word2vec_model.vector_size\n",
    "cmu_embedding_matrix = np.zeros((len(cmu_word_index) + 1, cmu_embedding_dim))\n",
    "for word, i in cmu_word_index.items():\n",
    "    if word in word2vec_model:\n",
    "        cmu_embedding_matrix[i] = word2vec_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(cmu_word_index) + 1, cmu_embedding_dim, embeddings_initializer=Constant(\n",
    "    cmu_embedding_matrix), trainable=False))\n",
    "model.add(LSTM(128, dropout=0.25, recurrent_dropout=0.25, return_sequences=True))\n",
    "model.add(LSTM(64, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(Dense(len(cmu_mlb.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(cmu_X_train, cmu_y_train, batch_size=64, epochs=7, validation_data=(\n",
    "    cmu_X_test, cmu_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the CMU test set\n",
    "cmu_y_pred = model.predict(cmu_X_test)\n",
    "cmu_y_pred_classes = (cmu_y_pred > 0.35).astype(int)\n",
    "\n",
    "# Make predictions on the IMDb test set\n",
    "cmu_y_pred_imdb = model.predict(imdb_X_test)\n",
    "cmu_y_pred_imdb_classes = (cmu_y_pred_imdb > 0.35).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CMU embedding matrix\n",
    "\"\"\" imdb_embedding_dim = word2vec_model.vector_size\n",
    "imdb_embedding_matrix = np.zeros((len(imdb_word_index) + 1, imdb_embedding_dim))\n",
    "for word, i in imdb_word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        imdb_embedding_matrix[i] = word2vec_model.wv[word] \"\"\"\n",
    "\n",
    "# Create the Google News embedding matrix\n",
    "imdb_embedding_dim = word2vec_model.vector_size\n",
    "imdb_embedding_matrix = np.zeros((len(imdb_word_index) + 1, imdb_embedding_dim))\n",
    "for word, i in imdb_word_index.items():\n",
    "    if word in word2vec_model:\n",
    "        imdb_embedding_matrix[i] = word2vec_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(imdb_word_index) + 1, imdb_embedding_dim, embeddings_initializer=Constant(\n",
    "    imdb_embedding_matrix), trainable=False))\n",
    "model.add(LSTM(128, dropout=0.25, recurrent_dropout=0.25, return_sequences=True))\n",
    "model.add(LSTM(64, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(Dense(len(imdb_mlb.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(imdb_X_train, imdb_y_train, batch_size=64, epochs=7, validation_data=(\n",
    "    imdb_X_test, imdb_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the IMDb test set\n",
    "imdb_y_pred = model.predict(imdb_X_test)\n",
    "imdb_y_pred_classes = (imdb_y_pred > 0.35).astype(int)\n",
    "\n",
    "# Make predictions on the CMU test set\n",
    "imdb_y_pred_cmu = model.predict(cmu_X_test)\n",
    "imdb_y_pred_cmu_classes = (imdb_y_pred_cmu > 0.35).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU on CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "precision_micro = precision_score(cmu_y_test, cmu_y_pred_classes, average='micro')\n",
    "recall_micro = recall_score(cmu_y_test, cmu_y_pred_classes, average='micro')\n",
    "f1_micro = f1_score(cmu_y_test, cmu_y_pred_classes, average='micro')\n",
    "\n",
    "precision_macro = precision_score(cmu_y_test, cmu_y_pred_classes, average='macro')\n",
    "recall_macro = recall_score(cmu_y_test, cmu_y_pred_classes, average='macro')\n",
    "f1_macro = f1_score(cmu_y_test, cmu_y_pred_classes, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Micro Precision: {precision_micro}')\n",
    "print(f'Micro Recall: {recall_micro}')\n",
    "print(f'Micro F1-score: {f1_micro}')\n",
    "print()\n",
    "print(f'Macro Precision: {precision_macro}')\n",
    "print(f'Macro Recall: {recall_macro}')\n",
    "print(f'Macro F1-score: {f1_macro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for each genre\n",
    "cmu_genre_scores = {}\n",
    "for i, genre in enumerate(imdb_mlb.classes_):\n",
    "    genre_accuracy = accuracy_score(cmu_y_test[:, i], cmu_y_pred_classes[:, i])\n",
    "    genre_precision = precision_score(cmu_y_test[:, i], cmu_y_pred_classes[:, i])\n",
    "    genre_recall = recall_score(cmu_y_test[:, i], cmu_y_pred_classes[:, i])\n",
    "    genre_f1 = f1_score(cmu_y_test[:, i], cmu_y_pred_classes[:, i])\n",
    "    \n",
    "    cmu_genre_scores[genre] = {'Accuracy': genre_accuracy,\n",
    "                                'Precision': genre_precision,\n",
    "                                'Recall': genre_recall,\n",
    "                                'F1-score': genre_f1}\n",
    "\n",
    "# Print scores for each genre\n",
    "for genre, scores in cmu_genre_scores.items():\n",
    "    print(f'Genre: {genre}')\n",
    "    print(f'Accuracy: {scores[\"Accuracy\"]}')\n",
    "    print(f'Precision: {scores[\"Precision\"]}')\n",
    "    print(f'Recall: {scores[\"Recall\"]}')\n",
    "    print(f'F1-score: {scores[\"F1-score\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU on IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(imdb_y_test, cmu_y_pred_imdb_classes)\n",
    "precision = precision_score(imdb_y_test, cmu_y_pred_imdb_classes, average='micro')\n",
    "recall = recall_score(imdb_y_test, cmu_y_pred_imdb_classes, average='micro')\n",
    "f1 = f1_score(imdb_y_test, cmu_y_pred_imdb_classes, average='micro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for each genre\n",
    "genre_scores = {}\n",
    "for i, genre in enumerate(cmu_mlb.classes_):\n",
    "    genre_accuracy = accuracy_score(imdb_y_test[:, i], cmu_y_pred_imdb_classes[:, i])\n",
    "    genre_precision = precision_score(imdb_y_test[:, i], cmu_y_pred_imdb_classes[:, i])\n",
    "    genre_recall = recall_score(imdb_y_test[:, i], cmu_y_pred_imdb_classes[:, i])\n",
    "    genre_f1 = f1_score(imdb_y_test[:, i], cmu_y_pred_imdb_classes[:, i])\n",
    "    \n",
    "    genre_scores[genre] = {'Accuracy': genre_accuracy,\n",
    "                           'Precision': genre_precision,\n",
    "                           'Recall': genre_recall,\n",
    "                           'F1-score': genre_f1}\n",
    "\n",
    "# Print scores for each genre\n",
    "for genre, scores in genre_scores.items():\n",
    "    print(f'Genre: {genre}')\n",
    "    print(f'Accuracy: {scores[\"Accuracy\"]}')\n",
    "    print(f'Precision: {scores[\"Precision\"]}')\n",
    "    print(f'Recall: {scores[\"Recall\"]}')\n",
    "    print(f'F1-score: {scores[\"F1-score\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb on IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "precision_micro = precision_score(imdb_y_test, imdb_y_pred_classes, average='micro')\n",
    "recall_micro = recall_score(imdb_y_test, imdb_y_pred_classes, average='micro')\n",
    "f1_micro = f1_score(imdb_y_test, imdb_y_pred_classes, average='micro')\n",
    "\n",
    "precision_macro = precision_score(imdb_y_test, imdb_y_pred_classes, average='macro')\n",
    "recall_macro = recall_score(imdb_y_test, imdb_y_pred_classes, average='macro')\n",
    "f1_macro = f1_score(imdb_y_test, imdb_y_pred_classes, average='macro')\n",
    "\n",
    "print(f'Precision (micro): {precision_micro}')\n",
    "print(f'Recall (micro): {recall_micro}')\n",
    "print(f'F1-score (micro): {f1_micro}')\n",
    "print()\n",
    "print(f'Precision (macro): {precision_macro}')\n",
    "print(f'Recall (macro): {recall_macro}')\n",
    "print(f'F1-score (macro): {f1_macro}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for each genre\n",
    "imdb_genre_scores = {}\n",
    "for i, genre in enumerate(imdb_mlb.classes_):\n",
    "    genre_accuracy = accuracy_score(imdb_y_test[:, i], imdb_y_pred_classes[:, i])\n",
    "    genre_precision = precision_score(imdb_y_test[:, i], imdb_y_pred_classes[:, i])\n",
    "    genre_recall = recall_score(imdb_y_test[:, i], imdb_y_pred_classes[:, i])\n",
    "    genre_f1 = f1_score(imdb_y_test[:, i], imdb_y_pred_classes[:, i])\n",
    "    \n",
    "    imdb_genre_scores[genre] = {'Accuracy': genre_accuracy,\n",
    "                                'Precision': genre_precision,\n",
    "                                'Recall': genre_recall,\n",
    "                                'F1-score': genre_f1}\n",
    "\n",
    "# Print scores for each genre\n",
    "for genre, scores in imdb_genre_scores.items():\n",
    "    print(f'Genre: {genre}')\n",
    "    print(f'Accuracy: {scores[\"Accuracy\"]}')\n",
    "    print(f'Precision: {scores[\"Precision\"]}')\n",
    "    print(f'Recall: {scores[\"Recall\"]}')\n",
    "    print(f'F1-score: {scores[\"F1-score\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb on CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(cmu_y_test, imdb_y_pred_cmu_classes)\n",
    "precision = precision_score(cmu_y_test, imdb_y_pred_cmu_classes, average='micro')\n",
    "recall = recall_score(cmu_y_test, imdb_y_pred_cmu_classes, average='micro')\n",
    "f1 = f1_score(cmu_y_test, imdb_y_pred_cmu_classes, average='micro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for each genre\n",
    "imdb_genre_scores = {}\n",
    "for i, genre in enumerate(imdb_mlb.classes_):\n",
    "    genre_accuracy = accuracy_score(cmu_y_test[:, i], imdb_y_pred_cmu_classes[:, i])\n",
    "    genre_precision = precision_score(cmu_y_test[:, i], imdb_y_pred_cmu_classes[:, i])\n",
    "    genre_recall = recall_score(cmu_y_test[:, i], imdb_y_pred_cmu_classes[:, i])\n",
    "    genre_f1 = f1_score(cmu_y_test[:, i], imdb_y_pred_cmu_classes[:, i])\n",
    "    \n",
    "    imdb_genre_scores[genre] = {'Accuracy': genre_accuracy,\n",
    "                                'Precision': genre_precision,\n",
    "                                'Recall': genre_recall,\n",
    "                                'F1-score': genre_f1}\n",
    "\n",
    "# Print scores for each genre\n",
    "for genre, scores in imdb_genre_scores.items():\n",
    "    print(f'Genre: {genre}')\n",
    "    print(f'Accuracy: {scores[\"Accuracy\"]}')\n",
    "    print(f'Precision: {scores[\"Precision\"]}')\n",
    "    print(f'Recall: {scores[\"Recall\"]}')\n",
    "    print(f'F1-score: {scores[\"F1-score\"]}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
