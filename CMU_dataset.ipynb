{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "RANDOM_STATE = 1212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the CMU corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "cmu_corpus = pd.read_csv(\"movie.metadata.tsv\", sep=\"\\t\", header=None)\n",
    "cmu_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column names to the dataset, pruning unnecessary columns\n",
    "cmu_corpus.columns = [\"movie_id\", 1 ,\"movie_name\", \"year\", 4, 5, 6, 7, \"genre\"]\n",
    "cmu_corpus[\"year\"] = cmu_corpus[\"year\"].astype(str).str[:4]\n",
    "\n",
    "cmu_corpus.drop([1, 4, 5, 6, 7], axis=1, inplace=True)\n",
    "cmu_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from plot_summaries.txt\n",
    "plot_summaries = pd.read_csv(\"plot_summaries.txt\", sep=\"\\t\", header=None)\n",
    "plot_summaries.columns = [\"movie_id\", \"plot\"]\n",
    "\n",
    "# Clean the plot summaries from citations and references\n",
    "plot_summaries['plot'] = plot_summaries['plot'].apply(\n",
    "    lambda x: re.sub(r'\\{.*?\\}|<ref.*\\}|\\{.*\\/>', '', x))\n",
    "\n",
    "# Remove URL's\n",
    "plot_summaries['plot'] = plot_summaries['plot'].apply(\n",
    "    lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "# Convert the 'movie_id' column in both dataframes to int\n",
    "cmu_corpus['movie_id'] = cmu_corpus['movie_id'].astype(int)\n",
    "plot_summaries['movie_id'] = plot_summaries['movie_id'].astype(int)\n",
    "\n",
    "# Revome all plot summaries with less than 2 sentences\n",
    "plot_summaries = plot_summaries[plot_summaries[\"plot\"].apply(lambda x: x.count(\".\") >= 2)]\n",
    "\n",
    "# Merging the dataframes on the 'movie_id' column\n",
    "cmu_corpus = pd.merge(cmu_corpus, plot_summaries, on=\"movie_id\")\n",
    "cmu_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the genre column\n",
    "\n",
    "genres = [] \n",
    "\n",
    "for i in cmu_corpus['genre']: \n",
    "  genres.append(list(json.loads(i).values())) \n",
    "\n",
    "cmu_corpus['genre_new'] = genres\n",
    "\n",
    "cmu_corpus.drop(columns=[\"genre\"], inplace=True)\n",
    "cmu_corpus.rename(columns={\"genre_new\": \"genre\"}, inplace=True)\n",
    "\n",
    "cmu_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the dataframe in the genre- and year columns and removing them\n",
    "cmu_movies = cmu_corpus[~(cmu_corpus['genre'].str.len() == 0)]\n",
    "cmu_movies = cmu_movies[~(cmu_movies['year'] == \"nan\")]\n",
    "cmu_movies.shape, cmu_corpus.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting together the CMU dataset.\n",
    "\n",
    "##### To create a testing dataset to work with, we take 1590 objects from each genre (thriller, horror, comedy and drama). All movies with overlapping genres are not included. First, we shuffle the dataset to limit any potential bias.\n",
    "\n",
    "##### All movies fitting the criterias are put in a backup dataset, movies from backup will be used for OMDb API calls to fill that dataset and later fill a matching CMU dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_movies = cmu_movies.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "comedy_movies = cmu_movies[cmu_movies['genre'].apply(lambda x: 'Comedy' in x and not any(genre in x for genre in ['Horror', 'Thriller', 'Drama']))]\n",
    "comedy_movies.loc[:, 'genre'] = 'Comedy'\n",
    "\n",
    "horror_movies = cmu_movies[cmu_movies['genre'].apply(lambda x: 'Horror' in x and not any(genre in x for genre in ['Comedy', 'Thriller', 'Drama']))]\n",
    "horror_movies.loc[:, 'genre'] = 'Horror'\n",
    "\n",
    "thriller_movies = cmu_movies[cmu_movies['genre'].apply(lambda x: 'Thriller' in x and not any(genre in x for genre in ['Horror', 'Comedy', 'Drama']))]\n",
    "thriller_movies.loc[:, 'genre'] = 'Thriller'\n",
    "\n",
    "drama_movies = cmu_movies[cmu_movies['genre'].apply(lambda x: 'Drama' in x and not any(genre in x for genre in ['Horror', 'Thriller', 'Comedy']))]\n",
    "drama_movies.loc[:, 'genre'] = 'Drama'\n",
    "\n",
    "cmu_backup = pd.concat([comedy_movies, horror_movies, thriller_movies, drama_movies])\n",
    "\n",
    "\n",
    "# Used to create a test dataset\n",
    "\n",
    "# cmu_dataset = pd.concat([comedy_movies.head(1590), horror_movies.head(1590), thriller_movies.head(1590), drama_movies.head(1590)])\n",
    "# cmu_dataset.reset_index(drop=True, inplace=True)\n",
    "# cmu_dataset.to_csv(\"cmu_dataset_v3.csv\", index=False)\n",
    "\n",
    "\n",
    "cmu_backup.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "cmu_backup.to_csv(\"cmu_backup.csv\", index=False)\n",
    "\n",
    "cmu_backup.shape, comedy_movies.shape, horror_movies.shape, thriller_movies.shape, drama_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY RUN THIS AFTER COMPLETING THE IMDb DATASET - THIS WILL TRY TO MATCH THE MOVIES FROM IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching columns with the imdb dataset\n",
    "imdb = pd.read_csv(\"imdb_data_final.csv\")\n",
    "\n",
    "cmu_backup = pd.read_csv(\"cmu_backup.csv\")\n",
    "\n",
    "cmu_backup.drop(columns=[\"movie_id\"], inplace=True)\n",
    "\n",
    "cmu_backup = cmu_backup[[\"movie_name\", \"year\", \"genre\", \"plot\"]]\n",
    "\n",
    "cmu_backup['year'] = cmu_backup['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.shape, cmu_backup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_backup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add every movie from the imdb dataset to the cmu dataset from cmu_backup\n",
    "\n",
    "cmu = pd.DataFrame(columns=[\"movie_name\", \"year\", \"genre\", \"plot\"])\n",
    "\n",
    "for index, row in imdb.iterrows():\n",
    "    movie_name = row[\"movie_name\"]\n",
    "    year = row[\"year\"]\n",
    "    genre = row[\"genre\"]\n",
    "    plot = row[\"plot\"]\n",
    "\n",
    "    if cmu_backup[(cmu_backup[\"movie_name\"] == movie_name) & (cmu_backup[\"year\"] == year) & (cmu_backup[\"genre\"] == genre)].shape[0] > 0:\n",
    "        cmu = pd.concat([cmu, cmu_backup[(cmu_backup[\"movie_name\"] == movie_name) & (cmu_backup[\"year\"] == year) & (cmu_backup[\"genre\"] == genre)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu.to_csv(\"cmu_data_final_Vx.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
